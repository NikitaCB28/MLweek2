{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vN1nRMLZYrgT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess images\n",
        "image_size = (64, 64)\n",
        "batch_size = 32\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the correct file path in your Google Drive\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/homer_bart'\n",
        "data_dir = \"/content/drive/My Drive/Colab Notebooks/homer_bart\"  # Replace with your images directory\n",
        "def load_images(data_dir, image_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_name in os.listdir(data_dir):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, img_name)\n",
        "                image = Image.open(img_path).resize(image_size)\n",
        "                images.append(np.array(image))\n",
        "                labels.append(class_name)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images(data_dir, image_size)\n",
        "\n",
        "# Encode labels\n",
        "label_map = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
        "labels = np.array([label_map[label] for label in labels])\n",
        "\n",
        "# Normalize images\n",
        "images = images / 255.0\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr_tH_w1ZH-v",
        "outputId": "3b7f2b9f-2faf-4eab-a88c-0fa95f647465"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(64, 64, 3)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "CQ_3COITdeHI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=batch_size, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccOKtw0Dboyn",
        "outputId": "7ad78933-d989-44ad-e3cf-9742a4eb8e7a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 1s 23ms/step - loss: 2.5203 - accuracy: 0.5578\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.5631 - accuracy: 0.7371\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.5790 - accuracy: 0.7131\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.5714 - accuracy: 0.7371\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4194 - accuracy: 0.7849\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4350 - accuracy: 0.8008\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3832 - accuracy: 0.7968\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3944 - accuracy: 0.8127\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3681 - accuracy: 0.8127\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3270 - accuracy: 0.8367\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4127 - accuracy: 0.8127\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5396 - accuracy: 0.7450\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3215 - accuracy: 0.8526\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2352 - accuracy: 0.8964\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2289 - accuracy: 0.9163\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3929 - accuracy: 0.8127\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.2513 - accuracy: 0.8805\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2769 - accuracy: 0.8606\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2207 - accuracy: 0.9163\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1716 - accuracy: 0.9602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_accuracy:.2f}')\n",
        "\n",
        "if test_accuracy > 0.8:\n",
        "    print(\"Test accuracy is greater than 80%, assignment passed!\")\n",
        "else:\n",
        "    print(\"Test accuracy is less than 80%, assignment failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnAqOjBgbr8k",
        "outputId": "23de6a33-beb3-41e8-d4ac-e63413919784"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 0.4035 - accuracy: 0.8929 - 167ms/epoch - 167ms/step\n",
            "\n",
            "Test accuracy: 0.89\n",
            "Test accuracy is greater than 80%, assignment passed!\n"
          ]
        }
      ]
    }
  ]
}